/// <reference types="node" />
import * as fs from 'fs';
import type { Writable } from 'stream';
import type * as RDF from '@rdfjs/types';
/**
 * A parallel file writer enables the writing to an infinite number of files in parallel.
 *
 * It works around system I/O limitations regarding the maximum number of open file descriptors
 * by internally only having a certain number of open file streams,
 * and intelligently closing/re-opening streams when needed using an LRU strategy.
 */
export declare class ParallelFileWriter {
    private readonly cache;
    private readonly lock;
    private fileClosingPromises;
    constructor(options: IParallelFileWriterOptions);
    /**
     * Get a write stream that accepts RDF/JS quads for the given file path.
     * It will automatically be serialized to the RDF format of the given content type.
     *
     * The returned stream is only safe to use until another call to this method.
     *
     * This is safe with regards to non-existing folders.
     * If any of the parent folders do not exist, they will be created.
     *
     * @param path Path to the file to write to.
     * @param contentType The content type to serialize for.
     *                    Note that this only should be content types that enable appending
     */
    getWriteStream(path: string, contentType: string): Promise<RDF.Stream & Writable>;
    protected getWriteStreamUnsafe(path: string, contentType: string): Promise<RDF.Stream & Writable>;
    /**
     * Close all open streams.
     */
    close(): Promise<void>;
    protected closeWriteEntry(path: string, writeEntry: IWriteEntry): void;
}
export interface IWriteEntry {
    writeStream: RDF.Stream & Writable;
    fileStream: fs.WriteStream;
}
export interface IParallelFileWriterOptions {
    streams: number;
}
